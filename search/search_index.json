{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Welcome to the Skit tech team's onboarding curriculum. The curriculum is a set of guided exercises to help you get onboarded on our technology and make a move towards delivering high quality enterprise grade AI software. It is not a reference manual, nor is it a styleguide for our tech stack. There are four parts in the curriculum covering various aspects of building the kind of AI software we develop. We believe the skills developed in these will help you do your job better, irrespective of your team. Each part has various sections, each section has few exercises to do. These exercises might require you to read up some content which will be provided in the section itself. Note While there are few exercises that can be picked up independently, we recommend going through them sequentially. To get started, fork this repository under your github profile. Code snippet for starting with an exercise are provided in the ./exercises directory in the repository root. Once you are ready, go the first part on building .","title":"Introduction"},{"location":"#introduction","text":"Welcome to the Skit tech team's onboarding curriculum. The curriculum is a set of guided exercises to help you get onboarded on our technology and make a move towards delivering high quality enterprise grade AI software. It is not a reference manual, nor is it a styleguide for our tech stack. There are four parts in the curriculum covering various aspects of building the kind of AI software we develop. We believe the skills developed in these will help you do your job better, irrespective of your team. Each part has various sections, each section has few exercises to do. These exercises might require you to read up some content which will be provided in the section itself. Note While there are few exercises that can be picked up independently, we recommend going through them sequentially. To get started, fork this repository under your github profile. Code snippet for starting with an exercise are provided in the ./exercises directory in the repository root. Once you are ready, go the first part on building .","title":"Introduction"},{"location":"building/","text":"Building Welcome to the building curriculum. Here we work on basic building blocks of softwares. We will make shippable packages, CLI tools, APIs etc. Note Majority of our software is written in Python and Golang. You can use any of these languages to work on the exercises. When we provide any code snippet, we provide language tabs like below so you can work with your preferred langauge. Python if __name__ == \"__main__\" : print ( \"Hello world\" ) Go package main import \"fmt\" func main () { fmt . Println ( \"Hello world\" ) }","title":"Building"},{"location":"building/#building","text":"Welcome to the building curriculum. Here we work on basic building blocks of softwares. We will make shippable packages, CLI tools, APIs etc. Note Majority of our software is written in Python and Golang. You can use any of these languages to work on the exercises. When we provide any code snippet, we provide language tabs like below so you can work with your preferred langauge. Python if __name__ == \"__main__\" : print ( \"Hello world\" ) Go package main import \"fmt\" func main () { fmt . Println ( \"Hello world\" ) }","title":"Building"},{"location":"building/01/","text":"FFtrim Your first assignment is to build a command line tool named fftrim which replicates FFmpeg's media trimming capabilities. FFmpeg is versatile tool for media manipulation. If you work with speech data of any sort, you will be sleeping happily in nights knowing that FFmpeg exists. In fftrim , we want to minimally replicate audio trimming feature that works like the following: fftrim -i <input-file> -ss <start-time> -to <end-time> <output-file> fftrim -i <input-file> -ss <start-time> -t <duration> <output-file> # All time units are in seconds Few notes on the assignment: Your CLI tool should be installable via your language's standard method and provide a command in shell, post installation. fftrim should preserve the audio format and encoding. Do not call ffmpeg as subprocess. The idea is for you to understand as much as possible about audio data representation so try reading the input using a decoding library and work from there. Note Since this is merely an instructional program, don't put the package on public package indices like PyPI . Instead, just provide instructions on building and installing the package system wide for usage. Once you have built the package, run the test cases to ensure that your program does what it's supposed to do. You can run tests by running make test in the exercise root. Warning Tests for this exercise are not working as of now. You are encouraged to listen to the generated audios to see if the tool is working as expected. Also feel free to do a pull request for fixing the tests. Resources Few resources that you might want to follow for working on this: Python packaging and Poetry SoundFile cli and docopt Working with audio data","title":"FFtrim"},{"location":"building/01/#fftrim","text":"Your first assignment is to build a command line tool named fftrim which replicates FFmpeg's media trimming capabilities. FFmpeg is versatile tool for media manipulation. If you work with speech data of any sort, you will be sleeping happily in nights knowing that FFmpeg exists. In fftrim , we want to minimally replicate audio trimming feature that works like the following: fftrim -i <input-file> -ss <start-time> -to <end-time> <output-file> fftrim -i <input-file> -ss <start-time> -t <duration> <output-file> # All time units are in seconds Few notes on the assignment: Your CLI tool should be installable via your language's standard method and provide a command in shell, post installation. fftrim should preserve the audio format and encoding. Do not call ffmpeg as subprocess. The idea is for you to understand as much as possible about audio data representation so try reading the input using a decoding library and work from there. Note Since this is merely an instructional program, don't put the package on public package indices like PyPI . Instead, just provide instructions on building and installing the package system wide for usage. Once you have built the package, run the test cases to ensure that your program does what it's supposed to do. You can run tests by running make test in the exercise root. Warning Tests for this exercise are not working as of now. You are encouraged to listen to the generated audios to see if the tool is working as expected. Also feel free to do a pull request for fixing the tests.","title":"FFtrim"},{"location":"building/01/#resources","text":"Few resources that you might want to follow for working on this: Python packaging and Poetry SoundFile cli and docopt Working with audio data","title":"Resources"},{"location":"building/02/","text":"FFtrim Service This assignment is to build an HTTP service named fftrim-http-service which will be an extension to the fftrim assignment . You'll need to interface your fftrim tool via HTTP APIs so one can request these APIs and perform the same operations as the fftrim CLI tool. Here are the APIs which you need to implement: POST /api/trim/ Request Following are the parameters you would need to pass to this API as query parameters, request body etc. Request query parameters - start_time - end_time - duration Request body - audio as binary data Response audio as binary data You can also add any other relevant information you wish to send in the response. Note Audio in request/response to/from this API need to be the raw audio data and not an external reference to the audio file. Resources Few resources that you might want to follow for working on this: HTTP POST Multipart request","title":"FFtrim Service"},{"location":"building/02/#fftrim-service","text":"This assignment is to build an HTTP service named fftrim-http-service which will be an extension to the fftrim assignment . You'll need to interface your fftrim tool via HTTP APIs so one can request these APIs and perform the same operations as the fftrim CLI tool. Here are the APIs which you need to implement:","title":"FFtrim Service"},{"location":"building/02/#post-apitrim","text":"","title":"POST /api/trim/"},{"location":"building/02/#request","text":"Following are the parameters you would need to pass to this API as query parameters, request body etc. Request query parameters - start_time - end_time - duration Request body - audio as binary data","title":"Request"},{"location":"building/02/#response","text":"audio as binary data You can also add any other relevant information you wish to send in the response. Note Audio in request/response to/from this API need to be the raw audio data and not an external reference to the audio file.","title":"Response"},{"location":"building/02/#resources","text":"Few resources that you might want to follow for working on this: HTTP POST Multipart request","title":"Resources"},{"location":"building/03/","text":"FFtrim gRPC Service This assignment is to build an gRPC service named fftrim-grpc-service which will be an extension to the fftrim assignment . You'll need to interface your fftrim tool via gRPC endpoints so one can request these endpoints and perform the same operations as the fftrim CLI tool. Here's the protobuf definition which should be the reference for the service you create: syntax = \"proto3\" ; package fftrim_grpc_service ; service FFTrimService { rpc Trim ( TrimRequest ) returns ( TrimResponse ) {} } message TrimRequest { TrimConfig config = 1 ; bytes audio = 2 ; } message TrimConfig { int16 start_time = 1 ; int16 end_time = 2 ; int16 duration = 3 ; } message TrimResponse { bytes audio = 1 ; } Use this proto to compile and generate code and stubs for Python/Golang. Python For Python you can do something like below to generate Python code from the proto definitions: python -m grpc_tools.protoc -I. --python_out = . --grpc_python_out = . fftrim.proto Go protoc -I. -I /usr/local/include/ --go_out = plugins = grpc:. --proto_path = . labels.proto Feel free to add/remove items in the proto definition you feel is relevant and wish to send in the request/response. Note Audio in request/response to/from this API need to be the raw audio data and not an external reference to the audio file. Resources Few resources that you might want to follow for working on this: Basics: gRPC using Python Basics: gRPC using Go Protobuf","title":"FFtrim gRPC Service"},{"location":"building/03/#fftrim-grpc-service","text":"This assignment is to build an gRPC service named fftrim-grpc-service which will be an extension to the fftrim assignment . You'll need to interface your fftrim tool via gRPC endpoints so one can request these endpoints and perform the same operations as the fftrim CLI tool. Here's the protobuf definition which should be the reference for the service you create: syntax = \"proto3\" ; package fftrim_grpc_service ; service FFTrimService { rpc Trim ( TrimRequest ) returns ( TrimResponse ) {} } message TrimRequest { TrimConfig config = 1 ; bytes audio = 2 ; } message TrimConfig { int16 start_time = 1 ; int16 end_time = 2 ; int16 duration = 3 ; } message TrimResponse { bytes audio = 1 ; } Use this proto to compile and generate code and stubs for Python/Golang.","title":"FFtrim gRPC Service"},{"location":"building/03/#python","text":"For Python you can do something like below to generate Python code from the proto definitions: python -m grpc_tools.protoc -I. --python_out = . --grpc_python_out = . fftrim.proto","title":"Python"},{"location":"building/03/#go","text":"protoc -I. -I /usr/local/include/ --go_out = plugins = grpc:. --proto_path = . labels.proto Feel free to add/remove items in the proto definition you feel is relevant and wish to send in the request/response. Note Audio in request/response to/from this API need to be the raw audio data and not an external reference to the audio file.","title":"Go"},{"location":"building/03/#resources","text":"Few resources that you might want to follow for working on this: Basics: gRPC using Python Basics: gRPC using Go Protobuf","title":"Resources"},{"location":"debug/python_code_debugging/","text":"What is debugging? Debugging is an action of removing issues or potential errors that can cause your code to crash or have unexpected behavior. So this post is about ways to debug code. Programming allows you to think about thinking, and while debugging you learn learning. Here are some of the ways you can debug your code. Adding print statements or logger to your code Whenever writing code the best practice is to put enough print statements/loggers in the code so that if there are issues in they could be caught while the development process and get fixed. Here is an example of a piece of code with print statements def my_fact(numb) -> int: if numb is 1: return numb else: return numb * my_fact(numb - 1) if __name__ == '__main__': num = input(\"Enter the number you want to calculate factorial for: \") if isinstance(num, str): try: num = int(num) except ValueError as e: print(\"Unable to convert to integer, Exception: {}\".format(e)) else: print(\"Please input an Integer\") if isinstance(num, int): factorial = my_fact(num) print(\"Factorial is: {}\".format(factorial)) Another way to debug is adding loggers, one awesome library in python is Loguru, here is the same code snippet with loguru. from loguru import logger def my_fact(numb) -> int: if numb is 1: return numb else: return numb * my_fact(numb - 1) if __name__ == '__main__': num = input(\"Enter the number you want to calculate factorial for: \") if isinstance(num, str): try: num = int(num) except ValueError as e: logger.error(\"Unable to convert to integer, Exception: {}\".format(e)) else: logger.info(\"Please input an Integer\") if isinstance(num, int): factorial = my_fact(num) logger.debug(\"Factorial is: {}\".format(factorial)) The advantage to adding a logger is that you would know where the code is breaking and also most of the logger libraries have different levels of logging: info error debug Python PDB module The pdb module in python helps debug the source code. For python 2.7 and above there is a package called pdb which you can use for debugging your code. To use this you need to add import pdb; pdb.set_trace() to the code where you need to examine the variables and their value. This is just like adding a breakpoint to your code. A breakpoint is used for suspending the program execution, post that you can examine the code line by line. Following is the implementation of adding breakpoint: ... if isinstance(num, int): import pdb; pdb.set_trace() factorial = my_fact(num) Next, you need to run your code: python factorial.py Enter the number you want to calculate factorial for: 5 > /Users/dimplemathew/PycharmProjects/pythonProject2/factorial.py(23)<module>() -> factorial = my_fact(num) (Pdb) You will see something similar to \u261d\ufe0f in your terminal. It shows the path of the file along with the line number where the breakpoint is added. (Pdb) p num 5 Next to know the value of the variables you can use \u2018p to get the value. If you are using python 3 and above you need not import pdb instead just add a breakpoint() where every you want in your source code. Below is the implementation: ... if isinstance(num, int): breakpoint() factorial = my_fact(num) For further read, here is the link to the documentation","title":"What is debugging?"},{"location":"debug/python_code_debugging/#what-is-debugging","text":"Debugging is an action of removing issues or potential errors that can cause your code to crash or have unexpected behavior. So this post is about ways to debug code. Programming allows you to think about thinking, and while debugging you learn learning. Here are some of the ways you can debug your code. Adding print statements or logger to your code Whenever writing code the best practice is to put enough print statements/loggers in the code so that if there are issues in they could be caught while the development process and get fixed. Here is an example of a piece of code with print statements def my_fact(numb) -> int: if numb is 1: return numb else: return numb * my_fact(numb - 1) if __name__ == '__main__': num = input(\"Enter the number you want to calculate factorial for: \") if isinstance(num, str): try: num = int(num) except ValueError as e: print(\"Unable to convert to integer, Exception: {}\".format(e)) else: print(\"Please input an Integer\") if isinstance(num, int): factorial = my_fact(num) print(\"Factorial is: {}\".format(factorial)) Another way to debug is adding loggers, one awesome library in python is Loguru, here is the same code snippet with loguru. from loguru import logger def my_fact(numb) -> int: if numb is 1: return numb else: return numb * my_fact(numb - 1) if __name__ == '__main__': num = input(\"Enter the number you want to calculate factorial for: \") if isinstance(num, str): try: num = int(num) except ValueError as e: logger.error(\"Unable to convert to integer, Exception: {}\".format(e)) else: logger.info(\"Please input an Integer\") if isinstance(num, int): factorial = my_fact(num) logger.debug(\"Factorial is: {}\".format(factorial)) The advantage to adding a logger is that you would know where the code is breaking and also most of the logger libraries have different levels of logging: info error debug Python PDB module The pdb module in python helps debug the source code. For python 2.7 and above there is a package called pdb which you can use for debugging your code. To use this you need to add import pdb; pdb.set_trace() to the code where you need to examine the variables and their value. This is just like adding a breakpoint to your code. A breakpoint is used for suspending the program execution, post that you can examine the code line by line. Following is the implementation of adding breakpoint: ... if isinstance(num, int): import pdb; pdb.set_trace() factorial = my_fact(num) Next, you need to run your code: python factorial.py Enter the number you want to calculate factorial for: 5 > /Users/dimplemathew/PycharmProjects/pythonProject2/factorial.py(23)<module>() -> factorial = my_fact(num) (Pdb) You will see something similar to \u261d\ufe0f in your terminal. It shows the path of the file along with the line number where the breakpoint is added. (Pdb) p num 5 Next to know the value of the variables you can use \u2018p to get the value. If you are using python 3 and above you need not import pdb instead just add a breakpoint() where every you want in your source code. Below is the implementation: ... if isinstance(num, int): breakpoint() factorial = my_fact(num) For further read, here is the link to the documentation","title":"What is debugging?"},{"location":"deploying/","text":"Going Live Warning Work in Progress!","title":"Going Live"},{"location":"deploying/#going-live","text":"Warning Work in Progress!","title":"Going Live"},{"location":"deploying/ci_cd/","text":"CI/CD Continuous Integration and Continuous Deployment/Delivery are fundamental DevOps best pratices where developers merge changes into a central repository where automated builds and checks run and then auto-deployed. We run our CIs on GitLab and use ArgoCD to deploy code to our Kubernetes clusters. A thorough explanation of our CI/CD architecture and how to use it can be found here . Once you've gone through the documentation, here is a short exercise to help you get some hands-on experience with the process: Create a new repository on GitLab with the name <your-name>-starter-sample . Copy all files from skit-starter-sample (Forking a project under the same namespace in not available in GitLab) Modify the following line in main.py to print your message instead of Hello! cowsay.cow(\"Hello!\") Create an ECR repository with the name as <your-name>-starter-sample in AWS ECR. Go through and modify the .gitlab-ci.yml file by changing APP_NAME and SERVICE_NAME variables with your service name which is <your-name>-starter-sample Merge your changes and tag with v0.0.1-0.0.1 to trigger docker build and deploy steps. Once the image is built, confirm it's been uploaded in AWS ECR. Next, clone the k8s-configs . Create your own branch and copy the helm chart folder starter-sample and rename the folder to <your-name>-starter-sample . Change all occurrences of starter-sample to <your-name>-starter-sample in Chart.yaml , application-staging.yaml and values-staging.yaml . Merge your branch. Once the post-merge pipeline passes, search for your application in ArgoCD . It should be green and healthy. Check the logs to confirm if the cow is saying the text you've provided. Get the deployment verified by your buddy. Once the verification is done, complete the following cleanup activities: 1. Delete your deployment from ArgoCD using the Delete option in the UI. 2. Delete your helm chart from k8s-configs repository. 3. Delete the ECR repository created by you. 4. Delete your GitLab repository.","title":"CI/CD"},{"location":"deploying/ci_cd/#cicd","text":"Continuous Integration and Continuous Deployment/Delivery are fundamental DevOps best pratices where developers merge changes into a central repository where automated builds and checks run and then auto-deployed. We run our CIs on GitLab and use ArgoCD to deploy code to our Kubernetes clusters. A thorough explanation of our CI/CD architecture and how to use it can be found here . Once you've gone through the documentation, here is a short exercise to help you get some hands-on experience with the process: Create a new repository on GitLab with the name <your-name>-starter-sample . Copy all files from skit-starter-sample (Forking a project under the same namespace in not available in GitLab) Modify the following line in main.py to print your message instead of Hello! cowsay.cow(\"Hello!\") Create an ECR repository with the name as <your-name>-starter-sample in AWS ECR. Go through and modify the .gitlab-ci.yml file by changing APP_NAME and SERVICE_NAME variables with your service name which is <your-name>-starter-sample Merge your changes and tag with v0.0.1-0.0.1 to trigger docker build and deploy steps. Once the image is built, confirm it's been uploaded in AWS ECR. Next, clone the k8s-configs . Create your own branch and copy the helm chart folder starter-sample and rename the folder to <your-name>-starter-sample . Change all occurrences of starter-sample to <your-name>-starter-sample in Chart.yaml , application-staging.yaml and values-staging.yaml . Merge your branch. Once the post-merge pipeline passes, search for your application in ArgoCD . It should be green and healthy. Check the logs to confirm if the cow is saying the text you've provided. Get the deployment verified by your buddy. Once the verification is done, complete the following cleanup activities: 1. Delete your deployment from ArgoCD using the Delete option in the UI. 2. Delete your helm chart from k8s-configs repository. 3. Delete the ECR repository created by you. 4. Delete your GitLab repository.","title":"CI/CD"},{"location":"deploying/k8s_basics/","text":"Kubernetes, an Introduction This doc is an attempt to give you a crash course on how you can use Kubernetes. It will give you just enough knowledge to get started with being a consumer of the platform. We will not be delving into the depths of components that make up this platform. This is as gentle an introduction as can be given. What is Kubernetes ? Kubernetes is a portable, extensible, open-source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. It has a large, rapidly growing ecosystem. Kubernetes services, support, and tools are widely available. ( source ) Components When you deploy Kubernetes, you get a cluster. This cluster can be divided into 2 parts: Component Purpose Control Pane This part of your cluster handles the orchestration and management of your deployed components. They effectively manage all the nodes. Nodes A Kubernetes cluster consists of a set of worker machines, called nodes, that run containerized applications. Every cluster has at least one worker node. For the rest of this doc, we'll only be concentrating on the Kubernetes objects you can deploy on nodes so that you can familiarize yourself with the basics here. Basic Kubernetes Objects Here, we'll attempt to go through the most commonly used Kubernetes objects. Kubernetes runs your workload by placing containers into \"Pods\" to run on Nodes. A node may be a virtual or physical machine, depending on the cluster. Each node is managed by the control plane and contains the services necessary to run Pods. The above image shows you a basic architecture of how an application with 3 replicas is deployed in Kubernetes and all the Kubernetes objects associated with it. This application has certain secrets and configurations which are stored by leveraging the objects Kubernetes provides for that very purpose. Object Description Node A Kubernetes cluster is a set of nodes that run containerised applications. The node itself can be called a unit of hardware assigned to the cluster on which applications run. There may be multiple such units. For AWS, this is an EC2 instance. Deployment Controls the container, pod and replica configuration. Auto-creates a ReplicaSet object and pod objects. Pod Pods are where docker containers run. Resource config of the deployment object will decide CPU and Memory allocated to each pod. All containers within the pod share these resources. Service Enables network access to a set of Pods in Kubernetes. Services select Pods based on their labels. When a network request is made to the service, it selects all Pods in the cluster matching the service's selector, chooses one of them, and forwards the network request to it. Service creation automatically creates an endpoint object locally to maintain the IP address mapping of the pods with the K8s cluster. Secret Objects which are simple key/value stores where you can keep sensitive data. Values are stored in base64 format. You can use the key from any secret object to inject the secret value into your pod. Configmap Like secrets, these too are key/value stores where you can keep configurations. Values are stored in plain text. A closer look at the Service object The service object is slightly different from all the other objects listed above. It is used to access the pods within the Kubernetes cluster and if required, outside of it as well. Difference between a service and a deployment: * The deployment is tasked with keeping the desired number of pods running. * The service enables network access to a set of pods. The number of pods can be scaled up and scaled down by making appropriate changes to the deployment. The pod names or IPs themselves can be used to access them individually. However, since they're ephemeral in nature, pods are always spawned with new names as well as possibly new IP addresses. Hence, the service object is an abstraction that maps to a set of pods to solve this problem. The mapping may span a single deployment or multiple deployment objects based on how the service itself is configured. A request to the service object is then routed to the pods it's mapped to. Resources Used Kubernetes Documentation Service - Kubernetes Guide with Examples","title":"K8s basics"},{"location":"deploying/k8s_basics/#kubernetes-an-introduction","text":"This doc is an attempt to give you a crash course on how you can use Kubernetes. It will give you just enough knowledge to get started with being a consumer of the platform. We will not be delving into the depths of components that make up this platform. This is as gentle an introduction as can be given.","title":"Kubernetes, an Introduction"},{"location":"deploying/k8s_basics/#what-is-kubernetes","text":"Kubernetes is a portable, extensible, open-source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. It has a large, rapidly growing ecosystem. Kubernetes services, support, and tools are widely available. ( source )","title":"What is Kubernetes ?"},{"location":"deploying/k8s_basics/#components","text":"When you deploy Kubernetes, you get a cluster. This cluster can be divided into 2 parts: Component Purpose Control Pane This part of your cluster handles the orchestration and management of your deployed components. They effectively manage all the nodes. Nodes A Kubernetes cluster consists of a set of worker machines, called nodes, that run containerized applications. Every cluster has at least one worker node. For the rest of this doc, we'll only be concentrating on the Kubernetes objects you can deploy on nodes so that you can familiarize yourself with the basics here.","title":"Components"},{"location":"deploying/k8s_basics/#basic-kubernetes-objects","text":"Here, we'll attempt to go through the most commonly used Kubernetes objects. Kubernetes runs your workload by placing containers into \"Pods\" to run on Nodes. A node may be a virtual or physical machine, depending on the cluster. Each node is managed by the control plane and contains the services necessary to run Pods. The above image shows you a basic architecture of how an application with 3 replicas is deployed in Kubernetes and all the Kubernetes objects associated with it. This application has certain secrets and configurations which are stored by leveraging the objects Kubernetes provides for that very purpose. Object Description Node A Kubernetes cluster is a set of nodes that run containerised applications. The node itself can be called a unit of hardware assigned to the cluster on which applications run. There may be multiple such units. For AWS, this is an EC2 instance. Deployment Controls the container, pod and replica configuration. Auto-creates a ReplicaSet object and pod objects. Pod Pods are where docker containers run. Resource config of the deployment object will decide CPU and Memory allocated to each pod. All containers within the pod share these resources. Service Enables network access to a set of Pods in Kubernetes. Services select Pods based on their labels. When a network request is made to the service, it selects all Pods in the cluster matching the service's selector, chooses one of them, and forwards the network request to it. Service creation automatically creates an endpoint object locally to maintain the IP address mapping of the pods with the K8s cluster. Secret Objects which are simple key/value stores where you can keep sensitive data. Values are stored in base64 format. You can use the key from any secret object to inject the secret value into your pod. Configmap Like secrets, these too are key/value stores where you can keep configurations. Values are stored in plain text.","title":"Basic Kubernetes Objects"},{"location":"deploying/k8s_basics/#a-closer-look-at-the-service-object","text":"The service object is slightly different from all the other objects listed above. It is used to access the pods within the Kubernetes cluster and if required, outside of it as well. Difference between a service and a deployment: * The deployment is tasked with keeping the desired number of pods running. * The service enables network access to a set of pods. The number of pods can be scaled up and scaled down by making appropriate changes to the deployment. The pod names or IPs themselves can be used to access them individually. However, since they're ephemeral in nature, pods are always spawned with new names as well as possibly new IP addresses. Hence, the service object is an abstraction that maps to a set of pods to solve this problem. The mapping may span a single deployment or multiple deployment objects based on how the service itself is configured. A request to the service object is then routed to the pods it's mapped to.","title":"A closer look at the Service object"},{"location":"deploying/k8s_basics/#resources-used","text":"Kubernetes Documentation Service - Kubernetes Guide with Examples","title":"Resources Used"},{"location":"feature-flags/","text":"Feature Flags The basic idea behind feature flags is to turn a particular feature on/off based on some flag, or condition. A simple pseudocode translation can be: if useNewCoolFeature == true { newCoolFeature() } else { sameOldBehaviour() } This pseudocode demonstrates a simple statement that checks if a \"new cool feature\" is enabled. If it is, the behaviour of the new feature is observed, and if it isn't, nothing new happens and everything works as it had previously. Feature flags are essentially \"if statements\" that allows you to validate your new features and test out their functionalities, thus minimizing risks without much disruptions. When this code is deployed to production, it will be deployed as usual. However, it will remain inactive until the feature flag is explicitly activated. Now that you understand the basic idea behind feature flags, let's get you set up for an exercise to get you familiar with a few practices and an amazing tool Flagr . Setting you up Clone the following repository: https://gitlab.com/vernacularai/tools/curriculum-feature-flag Enter the cloned directory and run: go run main.go and make an HTTP request: curl --location --request GET 'localhost:8080' You should get the text Hello! in the response. An example Feature flag Assume you're developing a new feature in which instead of just returning a simple Hello! message, you want to send something more friendly like Hello! Have fun with this excercise! . But you are not sure if this is a good idea and want to validate it first with some, say 10%, of your users. This \"new feature\" is already implemented with a make-do feature flag and all you need to do is update its rollout percentage. Do: curl --location --request PUT 'localhost:8080/rollout/10' You may enter any float value, less than 100, for the new rollout percentage. This will tell our service to send the new message to 10% of all our users, after which you will use some metric to calculate its success. Now all that's left is to check if our feature flag is actually working. Manually make the \"hello\" request for a sufficient number of times and compare the number times your new feature works with those times it didn't. The ratio should roughly amount to the rollout percentage you provided as an input. curl --location --request PUT 'localhost:8080/rollout/10' Targetted testing Suppose you're a part of an MNC with clients in Russia. There, your service says \"Hello!\" in Russian as \"Privyet!\". Since \"Privyet\" is like an informal \"Hi\" and you would like to test if saying a more formal \"Zdrastvuyte\", which is also Russian for \"Hello\", you implement a feature flag that rollouts this new feature to 40% of the Russian clients. Also, to identify a Russian client, your service uses a query param ?location=ru . Let's test out our existing Russian \"Hello\" first: curl --location --request GET 'localhost:8080?location=ru' You'll get \"Privyet\" in Cyrillic script, which is the writing system used for the Russian language, in the response message. Update the rollout percentage for Russia too: curl --location --request PUT 'localhost:8080/rollout/40?location=ru' Test out our feature flag for Russian clients similar to the previous example and compare the responses to confirm if the rollout is similar to what was provided in input. Flagr Flagr is a great tool for implementing feature flags and A/B testing. You'll be employing it for continuing the rest of this exercise. Be sure to go through its For using Flagr, let's dial our use case up a notch. Suppose your MNC now serves clients in multiple regions throughout the world, with each region having any number of languages and people of different ages. Currently, you respond with a \"Hello\" indiscriminately but your product manager recently asked you to start tuning this greeting for various combinations of all these properties. The api that handles this greeting supports query params, location , lang and age , for identifying demographies concerning region, language and age respectively. The api you'll be is of the form: curl --location --request GET 'localhost:8080/flagr-hello?location=<region>&lang=<language>&age=<age>&key=<flagrKey> The query param \"key\" here is the flagKey of the flag you'll be creating shortly. Try making requests to the api. For example: curl --location --request GET 'localhost:8080/flagr-hello?lang=en&location=us&age=20&key=kzpo6597au5ivg876' You should get always get a message \"Hello!\" in response. We have a flagr instance hosted on our server that you can use. Ask #devops for: * URL for the hosted Flagr * Credentials for authenticating into the instance: username and password Stop the currently running exercise server on port 8080 and export the above values as environment variables: export FLAGR_URL = <FLAGR_URL> export FLAGR_USERNAME = <FLAGR_USERNAME> export FLAGR_PASSWORD = <FLAGR_PASSWORD> and start it again: go run main.go If you've added the environment variables correctly, you should have a valid Flagr client for employing your soon to be created new flag. Go to the hosted flagr on a browser and authenticate using the credentials you received. Create a new flag by giving it a name and clicking on the Create New Flag button. The new flag should be visible in the list now. Select it. You should now see the configuration page for the flag. Make note of your Flag Key . The next steps involve creating a \"Variant\" and a \"Segment\". Variant Variant represents the possible variation of a flag. For example, control/treatment, green/yellow/red, etc. It is any property that one would like to vary based on certain condition described in the \"Segments\". Enter a name for your variant in \"Key\" input box and click on \"Create Variant\". Select the \"Variant Attachment\" expansion panel and in the editor, enter the new message you'd like to show your audience. For example: { \"message\": \"Privyet\" } Save the variant and move to the \"Segments\" section. Segment Create a new segment by clicking on the \"New Segment\" button and then defining its description and rollout settings in the slider. The rollout defines the fraction of the control buckets that would be impacted by the new feature. The default is 50 and you can let it remain the same. On creating a new segment, you'll notice \"No constraints (ALL will pass)\" being displayed. This means since we haven't provided any constraints on our segment, all our requests will be a part of the control buckets. You may leave it to be empty for now. To finish our initial setup, we'll have to define a distribution among the variants for the segment. Click on \"edit\", select your variant's checkbox and use the slider to increase its percentage to 100. This means all our requests passing the segment will be distributed completely to the variant. Save the distribution and now make a request to the flagr-hello api endpoint. Make sure you have correctly initialised the environment variables and provided your flagKey in the ?key query param. If you initialised the rollout to 50% and the message in your variant says \"Privyet\", you should receive \"Privyet\" in response half the times you make a request. Further Customisation Create a new variant, and this time enter a new message, say \"Zdrastvuyte\". In your segment, add a constraint on the location to be Russia. You can do this by adding location in \"Property\" and the value as ru with the conditional == . Click on \"Add Constraint\" and save your segment. Now, edit your distibution with the both the variants having 50-50 fractions. You may increase your rollout to 100% if you want all your Russian users to be greeted in the new fashion only. Test your api and observe how your response messages are distributed. Make sure you provide ru in the ?location query param. If you followed all the steps correctly, you should get a mix of \"Zdrastvuyte\" and \"Privyet\", with a bit of \"Hello!\" too if the rollout was less than 100. Try playing around with your flag, customising your audience based on other properties like language and age and creating different segments for different demographic groups with their own distributions of different variants. When exploited to the fullest, you'll get to appreciate how handy Flagr is. I hope this exercise helped in your understanding of feature flags and made you gain more confidence in implementing them using Flagr.","title":"Feature Flags"},{"location":"feature-flags/#feature-flags","text":"The basic idea behind feature flags is to turn a particular feature on/off based on some flag, or condition. A simple pseudocode translation can be: if useNewCoolFeature == true { newCoolFeature() } else { sameOldBehaviour() } This pseudocode demonstrates a simple statement that checks if a \"new cool feature\" is enabled. If it is, the behaviour of the new feature is observed, and if it isn't, nothing new happens and everything works as it had previously. Feature flags are essentially \"if statements\" that allows you to validate your new features and test out their functionalities, thus minimizing risks without much disruptions. When this code is deployed to production, it will be deployed as usual. However, it will remain inactive until the feature flag is explicitly activated. Now that you understand the basic idea behind feature flags, let's get you set up for an exercise to get you familiar with a few practices and an amazing tool Flagr .","title":"Feature Flags"},{"location":"feature-flags/#setting-you-up","text":"Clone the following repository: https://gitlab.com/vernacularai/tools/curriculum-feature-flag Enter the cloned directory and run: go run main.go and make an HTTP request: curl --location --request GET 'localhost:8080' You should get the text Hello! in the response.","title":"Setting you up"},{"location":"feature-flags/#an-example-feature-flag","text":"Assume you're developing a new feature in which instead of just returning a simple Hello! message, you want to send something more friendly like Hello! Have fun with this excercise! . But you are not sure if this is a good idea and want to validate it first with some, say 10%, of your users. This \"new feature\" is already implemented with a make-do feature flag and all you need to do is update its rollout percentage. Do: curl --location --request PUT 'localhost:8080/rollout/10' You may enter any float value, less than 100, for the new rollout percentage. This will tell our service to send the new message to 10% of all our users, after which you will use some metric to calculate its success. Now all that's left is to check if our feature flag is actually working. Manually make the \"hello\" request for a sufficient number of times and compare the number times your new feature works with those times it didn't. The ratio should roughly amount to the rollout percentage you provided as an input. curl --location --request PUT 'localhost:8080/rollout/10'","title":"An example Feature flag"},{"location":"feature-flags/#targetted-testing","text":"Suppose you're a part of an MNC with clients in Russia. There, your service says \"Hello!\" in Russian as \"Privyet!\". Since \"Privyet\" is like an informal \"Hi\" and you would like to test if saying a more formal \"Zdrastvuyte\", which is also Russian for \"Hello\", you implement a feature flag that rollouts this new feature to 40% of the Russian clients. Also, to identify a Russian client, your service uses a query param ?location=ru . Let's test out our existing Russian \"Hello\" first: curl --location --request GET 'localhost:8080?location=ru' You'll get \"Privyet\" in Cyrillic script, which is the writing system used for the Russian language, in the response message. Update the rollout percentage for Russia too: curl --location --request PUT 'localhost:8080/rollout/40?location=ru' Test out our feature flag for Russian clients similar to the previous example and compare the responses to confirm if the rollout is similar to what was provided in input.","title":"Targetted testing"},{"location":"feature-flags/#flagr","text":"Flagr is a great tool for implementing feature flags and A/B testing. You'll be employing it for continuing the rest of this exercise. Be sure to go through its For using Flagr, let's dial our use case up a notch. Suppose your MNC now serves clients in multiple regions throughout the world, with each region having any number of languages and people of different ages. Currently, you respond with a \"Hello\" indiscriminately but your product manager recently asked you to start tuning this greeting for various combinations of all these properties. The api that handles this greeting supports query params, location , lang and age , for identifying demographies concerning region, language and age respectively. The api you'll be is of the form: curl --location --request GET 'localhost:8080/flagr-hello?location=<region>&lang=<language>&age=<age>&key=<flagrKey> The query param \"key\" here is the flagKey of the flag you'll be creating shortly. Try making requests to the api. For example: curl --location --request GET 'localhost:8080/flagr-hello?lang=en&location=us&age=20&key=kzpo6597au5ivg876' You should get always get a message \"Hello!\" in response. We have a flagr instance hosted on our server that you can use. Ask #devops for: * URL for the hosted Flagr * Credentials for authenticating into the instance: username and password Stop the currently running exercise server on port 8080 and export the above values as environment variables: export FLAGR_URL = <FLAGR_URL> export FLAGR_USERNAME = <FLAGR_USERNAME> export FLAGR_PASSWORD = <FLAGR_PASSWORD> and start it again: go run main.go If you've added the environment variables correctly, you should have a valid Flagr client for employing your soon to be created new flag. Go to the hosted flagr on a browser and authenticate using the credentials you received. Create a new flag by giving it a name and clicking on the Create New Flag button. The new flag should be visible in the list now. Select it. You should now see the configuration page for the flag. Make note of your Flag Key . The next steps involve creating a \"Variant\" and a \"Segment\".","title":"Flagr"},{"location":"feature-flags/#variant","text":"Variant represents the possible variation of a flag. For example, control/treatment, green/yellow/red, etc. It is any property that one would like to vary based on certain condition described in the \"Segments\". Enter a name for your variant in \"Key\" input box and click on \"Create Variant\". Select the \"Variant Attachment\" expansion panel and in the editor, enter the new message you'd like to show your audience. For example: { \"message\": \"Privyet\" } Save the variant and move to the \"Segments\" section.","title":"Variant"},{"location":"feature-flags/#segment","text":"Create a new segment by clicking on the \"New Segment\" button and then defining its description and rollout settings in the slider. The rollout defines the fraction of the control buckets that would be impacted by the new feature. The default is 50 and you can let it remain the same. On creating a new segment, you'll notice \"No constraints (ALL will pass)\" being displayed. This means since we haven't provided any constraints on our segment, all our requests will be a part of the control buckets. You may leave it to be empty for now. To finish our initial setup, we'll have to define a distribution among the variants for the segment. Click on \"edit\", select your variant's checkbox and use the slider to increase its percentage to 100. This means all our requests passing the segment will be distributed completely to the variant. Save the distribution and now make a request to the flagr-hello api endpoint. Make sure you have correctly initialised the environment variables and provided your flagKey in the ?key query param. If you initialised the rollout to 50% and the message in your variant says \"Privyet\", you should receive \"Privyet\" in response half the times you make a request.","title":"Segment"},{"location":"feature-flags/#further-customisation","text":"Create a new variant, and this time enter a new message, say \"Zdrastvuyte\". In your segment, add a constraint on the location to be Russia. You can do this by adding location in \"Property\" and the value as ru with the conditional == . Click on \"Add Constraint\" and save your segment. Now, edit your distibution with the both the variants having 50-50 fractions. You may increase your rollout to 100% if you want all your Russian users to be greeted in the new fashion only. Test your api and observe how your response messages are distributed. Make sure you provide ru in the ?location query param. If you followed all the steps correctly, you should get a mix of \"Zdrastvuyte\" and \"Privyet\", with a bit of \"Hello!\" too if the rollout was less than 100. Try playing around with your flag, customising your audience based on other properties like language and age and creating different segments for different demographic groups with their own distributions of different variants. When exploited to the fullest, you'll get to appreciate how handy Flagr is. I hope this exercise helped in your understanding of feature flags and made you gain more confidence in implementing them using Flagr.","title":"Further Customisation"},{"location":"http/","text":"HTTP Hypertext Transfer Protocol (HTTP) is an application-layer protocol for transmitting hypermedia documents, such as HTML. It was designed for communication between web browsers and web servers, but it can also be used for other purposes. HTTP follows a classical client-server model, with a client opening a connection to make a request, then waiting until it receives a response. HTTP is a stateless protocol, meaning that the server does not keep any data (state) between two requests. Though this is not entirely true since you can make it stateful with use of cookies and sessions. HTTP is a huge-impact, ever-evolving protocol with an equally long history. Here are the components that should help you start employing it: Overview One of the most in-depth and the go-to documentation repository is MDN Web Docs . It is a great learning resource for web developers used by Mozilla, Microsoft, Google, Samsung [1] and everywhere . MDN has a great tutorial for getting the basics of HTTP right, Overview of HTTP . It will walk you through the basics and help udnerstand what different aspects are involved. HTTP Methods HTTP defines a set of request methods to indicate the desired action to be performed for a given resource. Although they can also be nouns, these request methods are sometimes referred to as HTTP verbs. The most commonly used ones are GET, PUT, POST and DELETE. Together, these four methods make up the CRUD , i.e., Create-Read-Update-Delete, interface for a resource. Read about these and other methods here along with their specifications and browser support. Messages You need to pass information between clients and servers. This is done through HTTP messages. There are two types of messages: Request: Sent by the client Response: Sent by the server HTTP messages are text-based and consists of: Start Line/Status Line: The start line of responses are more appropriately called a status line. The start line for requests and responses consist differing information. Headers: HTTP header fields are a list of linefeed-separated HTTP data being sent and received by both the client program and server on every HTTP request. These headers are usually invisible to the end-user and are only visible to the backend programs and people maintaining the internet system. Body: The body of a message is usually where the major chunk of the message resides when large information is to be passed. This is where the contents of the associated resource resides. Read about the HTTP messages here . Status Codes HTTP response status codes indicate whether a specific HTTP request has been successfully completed. Responses are grouped in five classes: Informational responses (100\u2013199) Successful responses (200\u2013299) Redirects (300\u2013399) Client errors (400\u2013499) Server errors (500\u2013599) You can find the status codes defined by section 10 of RFC 2616 on MDN . HTTP with REST HTTP and REST are used interchangeably often. The reason is obvious, it's almost everytime a convention that when you use HTTP, you practice REST. It's true that HTTP and REST are two very different things. REST stands for Representational State Transfer. It was first described in Roy Fielding\u2019s now-famous dissertation . REST is not a standard or a specification. Instead, Fielding described REST as an architectural style for distributed hypermedia systems. He believed there are several attributes of a RESTful architecture that would make it ideal for large interconnected systems such as the internet. HTTP stands for HyperText Transfer Protocol, which is a standard with well-defined constraints. It's a protocol maintained by the Internet Engineering Task Force. While it is not the same as REST, it exhibits many features of a RESTful system. This is not by accident, as Roy Fielding was one of the original authors ofRFC for HTTP. It\u2019s important to remember that the use of HTTP is not required for a RESTful system. We do insist on it though. It just so happens that HTTP is a good starting because it exhibits many RESTful qualities. References [1] Wikipedia: MDN Web Docs","title":"HTTP"},{"location":"http/#http","text":"Hypertext Transfer Protocol (HTTP) is an application-layer protocol for transmitting hypermedia documents, such as HTML. It was designed for communication between web browsers and web servers, but it can also be used for other purposes. HTTP follows a classical client-server model, with a client opening a connection to make a request, then waiting until it receives a response. HTTP is a stateless protocol, meaning that the server does not keep any data (state) between two requests. Though this is not entirely true since you can make it stateful with use of cookies and sessions. HTTP is a huge-impact, ever-evolving protocol with an equally long history. Here are the components that should help you start employing it:","title":"HTTP"},{"location":"http/#overview","text":"One of the most in-depth and the go-to documentation repository is MDN Web Docs . It is a great learning resource for web developers used by Mozilla, Microsoft, Google, Samsung [1] and everywhere . MDN has a great tutorial for getting the basics of HTTP right, Overview of HTTP . It will walk you through the basics and help udnerstand what different aspects are involved.","title":"Overview"},{"location":"http/#http-methods","text":"HTTP defines a set of request methods to indicate the desired action to be performed for a given resource. Although they can also be nouns, these request methods are sometimes referred to as HTTP verbs. The most commonly used ones are GET, PUT, POST and DELETE. Together, these four methods make up the CRUD , i.e., Create-Read-Update-Delete, interface for a resource. Read about these and other methods here along with their specifications and browser support.","title":"HTTP Methods"},{"location":"http/#messages","text":"You need to pass information between clients and servers. This is done through HTTP messages. There are two types of messages: Request: Sent by the client Response: Sent by the server HTTP messages are text-based and consists of: Start Line/Status Line: The start line of responses are more appropriately called a status line. The start line for requests and responses consist differing information. Headers: HTTP header fields are a list of linefeed-separated HTTP data being sent and received by both the client program and server on every HTTP request. These headers are usually invisible to the end-user and are only visible to the backend programs and people maintaining the internet system. Body: The body of a message is usually where the major chunk of the message resides when large information is to be passed. This is where the contents of the associated resource resides. Read about the HTTP messages here .","title":"Messages"},{"location":"http/#status-codes","text":"HTTP response status codes indicate whether a specific HTTP request has been successfully completed. Responses are grouped in five classes: Informational responses (100\u2013199) Successful responses (200\u2013299) Redirects (300\u2013399) Client errors (400\u2013499) Server errors (500\u2013599) You can find the status codes defined by section 10 of RFC 2616 on MDN .","title":"Status Codes"},{"location":"http/#http-with-rest","text":"HTTP and REST are used interchangeably often. The reason is obvious, it's almost everytime a convention that when you use HTTP, you practice REST. It's true that HTTP and REST are two very different things. REST stands for Representational State Transfer. It was first described in Roy Fielding\u2019s now-famous dissertation . REST is not a standard or a specification. Instead, Fielding described REST as an architectural style for distributed hypermedia systems. He believed there are several attributes of a RESTful architecture that would make it ideal for large interconnected systems such as the internet. HTTP stands for HyperText Transfer Protocol, which is a standard with well-defined constraints. It's a protocol maintained by the Internet Engineering Task Force. While it is not the same as REST, it exhibits many features of a RESTful system. This is not by accident, as Roy Fielding was one of the original authors ofRFC for HTTP. It\u2019s important to remember that the use of HTTP is not required for a RESTful system. We do insist on it though. It just so happens that HTTP is a good starting because it exhibits many RESTful qualities.","title":"HTTP with REST"},{"location":"http/#references","text":"[1] Wikipedia: MDN Web Docs","title":"References"},{"location":"http/exercise/","text":"A Simple cURL Exercise Here's a simple cURL exercise to get you familiar with the basics. In this exercise you'll be communicating with a service having a public url which you can use to communicate with it using cURL . This public url is [https://curriculum-http-curl.skit.ai](https://curriculum-http-curl.skit.ai) , which will be referenced as BASE_URL from now onwards. So if the url of the login api is given as {{BASE_URL}}/login , it means https://curriculum-http-curl.skit.ai/login . The {{}} shows a variable. Most often, you'll have to replace these values with your own values similar to how it was done for {{BASE_URL}} . While going through the exercise, try typing every command out instead of just copy-pasting. Make sure you understand everything that you type and every bit of what you get in the response. Say hello to the service by running: curl --location -g --request GET '{{BASE_URL}}' The service is a mock employee record keeper using which you can create data of emplyees, fetch that data, update the data and remove it. Since this data can be sensitive, it also has a form of email-password authentication with a persistent jwt access token ( bearer token ). Employee An employee has the following properties: * Email: string * Password: string * ID: unsigned int * First name: string * Second name: string * Age: int * Address: object The address of an employee further has following properties: * City: string * State: string * Street: string * House number: string New Employee Now that you know what an employee looks like, let's get you started with creating a new one. Make this request from your terminal after replacing {{EMAIL}} and {{PASSWORD}} with that of your employee's. curl --location -g --request POST '{{BASE_URL}}/employees' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"email\": \"{{EMAIL}}\", \"password\": \"{{PASSWORD}}\", \"first_name\": \"{{FIRST_NAME}}\", \"second_name\": \"{{SECOND_NAME}}\" }' You may get a Email already exists message in response, which means the email you entered is already in use. In this case you will have to provide a new email which isn't already present in the system. If you get status code as 200, you've successfully created a new employee. Note down the ID of your employee and the returned bearer token as it will be needed for the rest of the exercise. Logging Out You've done a great job creating an entry for your employee and now you're tired. Let's log you out. Run this command after putting in your ID and access token curl --location -g --request POST '{{BASE_URL}}/logout/:ID' \\ --header 'Authorization: Bearer {{TOKEN}}' A status code of 200 means you've successfully logged out. Logging In You've created your employee, but now you want to update its address. Run this command and note down the newly returned access token curl --location -g --request POST '{{BASE_URL}}/login' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"email\": \"{{EMAIL}}\", \"password\": \"{{PASSWORD}}\" }' Update details You can update the following details of your employee: email, password and address. To update your employee's address, run the following command: curl --location -g --request PUT '{{BASE_URL}}/employee/:ID \\ --header 'Authorization: Bearer {{TOKEN}}' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"address\": { \"city\": \"{{CITY}}\", \"state\": \"{{STATE}}\", \"street\": \"{{STREET}}\", \"house_number\": \"{{HOUSE_NUMBER}}\" } }' Make sure you've replaced the variables with appropriate values. You may also update the password or email of your employee with a command similar to curl --location -g --request PUT '{{BASE_URL}}/employee/:ID \\ --header 'Authorization: Bearer {{TOKEN}}' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"email\": \"{{EMAIL}}\", \"password\": \"{{PASSWORD}}\" }' If you get the message Nothing updated , you probably didn't provide any new information. Let's now check if our employee's address has indeed been updated in our system. Fetch details of your Employee Running this command will give you the details of your employee, except the password of course. curl --location -g --request GET '{{BASE_URL}}/employee/:ID' \\ --header 'Authorization: Bearer {{TOKEN}}' Found any information wrong? You may update it! :) List all the Employees Running this command will give you a list of all the employees currently saved on the system. curl --location -g --request GET '{{BASE_URL}}/employees' \\ --header 'Authorization: Bearer {{TOKEN}}' Delete an Employee Just like getting hired, employees get fired all the time. You may fire yours by curl --location -g --request DELETE '{{BASE_URL}}/employee/:ID' \\ --header 'Authorization: Bearer {{TOKEN}}' This will completely remove the employee from the system. Play around The exercise should have now made you comfortable with the basics of http and using cURL. Try playing around with it a little and make sure understand what each line does.","title":"A Simple cURL Exercise"},{"location":"http/exercise/#a-simple-curl-exercise","text":"Here's a simple cURL exercise to get you familiar with the basics. In this exercise you'll be communicating with a service having a public url which you can use to communicate with it using cURL . This public url is [https://curriculum-http-curl.skit.ai](https://curriculum-http-curl.skit.ai) , which will be referenced as BASE_URL from now onwards. So if the url of the login api is given as {{BASE_URL}}/login , it means https://curriculum-http-curl.skit.ai/login . The {{}} shows a variable. Most often, you'll have to replace these values with your own values similar to how it was done for {{BASE_URL}} . While going through the exercise, try typing every command out instead of just copy-pasting. Make sure you understand everything that you type and every bit of what you get in the response. Say hello to the service by running: curl --location -g --request GET '{{BASE_URL}}' The service is a mock employee record keeper using which you can create data of emplyees, fetch that data, update the data and remove it. Since this data can be sensitive, it also has a form of email-password authentication with a persistent jwt access token ( bearer token ).","title":"A Simple cURL Exercise"},{"location":"http/exercise/#employee","text":"An employee has the following properties: * Email: string * Password: string * ID: unsigned int * First name: string * Second name: string * Age: int * Address: object The address of an employee further has following properties: * City: string * State: string * Street: string * House number: string","title":"Employee"},{"location":"http/exercise/#new-employee","text":"Now that you know what an employee looks like, let's get you started with creating a new one. Make this request from your terminal after replacing {{EMAIL}} and {{PASSWORD}} with that of your employee's. curl --location -g --request POST '{{BASE_URL}}/employees' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"email\": \"{{EMAIL}}\", \"password\": \"{{PASSWORD}}\", \"first_name\": \"{{FIRST_NAME}}\", \"second_name\": \"{{SECOND_NAME}}\" }' You may get a Email already exists message in response, which means the email you entered is already in use. In this case you will have to provide a new email which isn't already present in the system. If you get status code as 200, you've successfully created a new employee. Note down the ID of your employee and the returned bearer token as it will be needed for the rest of the exercise.","title":"New Employee"},{"location":"http/exercise/#logging-out","text":"You've done a great job creating an entry for your employee and now you're tired. Let's log you out. Run this command after putting in your ID and access token curl --location -g --request POST '{{BASE_URL}}/logout/:ID' \\ --header 'Authorization: Bearer {{TOKEN}}' A status code of 200 means you've successfully logged out.","title":"Logging Out"},{"location":"http/exercise/#logging-in","text":"You've created your employee, but now you want to update its address. Run this command and note down the newly returned access token curl --location -g --request POST '{{BASE_URL}}/login' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"email\": \"{{EMAIL}}\", \"password\": \"{{PASSWORD}}\" }'","title":"Logging In"},{"location":"http/exercise/#update-details","text":"You can update the following details of your employee: email, password and address. To update your employee's address, run the following command: curl --location -g --request PUT '{{BASE_URL}}/employee/:ID \\ --header 'Authorization: Bearer {{TOKEN}}' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"address\": { \"city\": \"{{CITY}}\", \"state\": \"{{STATE}}\", \"street\": \"{{STREET}}\", \"house_number\": \"{{HOUSE_NUMBER}}\" } }' Make sure you've replaced the variables with appropriate values. You may also update the password or email of your employee with a command similar to curl --location -g --request PUT '{{BASE_URL}}/employee/:ID \\ --header 'Authorization: Bearer {{TOKEN}}' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"email\": \"{{EMAIL}}\", \"password\": \"{{PASSWORD}}\" }' If you get the message Nothing updated , you probably didn't provide any new information. Let's now check if our employee's address has indeed been updated in our system.","title":"Update details"},{"location":"http/exercise/#fetch-details-of-your-employee","text":"Running this command will give you the details of your employee, except the password of course. curl --location -g --request GET '{{BASE_URL}}/employee/:ID' \\ --header 'Authorization: Bearer {{TOKEN}}' Found any information wrong? You may update it! :)","title":"Fetch details of your Employee"},{"location":"http/exercise/#list-all-the-employees","text":"Running this command will give you a list of all the employees currently saved on the system. curl --location -g --request GET '{{BASE_URL}}/employees' \\ --header 'Authorization: Bearer {{TOKEN}}'","title":"List all the Employees"},{"location":"http/exercise/#delete-an-employee","text":"Just like getting hired, employees get fired all the time. You may fire yours by curl --location -g --request DELETE '{{BASE_URL}}/employee/:ID' \\ --header 'Authorization: Bearer {{TOKEN}}' This will completely remove the employee from the system.","title":"Delete an Employee"},{"location":"http/exercise/#play-around","text":"The exercise should have now made you comfortable with the basics of http and using cURL. Try playing around with it a little and make sure understand what each line does.","title":"Play around"},{"location":"misc/","text":"Miscellaneous Programming Topics Warning Work in Progress!","title":"Miscellaneous Programming Topics"},{"location":"misc/#miscellaneous-programming-topics","text":"Warning Work in Progress!","title":"Miscellaneous Programming Topics"},{"location":"misc/01-parsing/","text":"Ink Language Parser Develop a simple parser in your preferred programming language that can read and interpret basic constructs of the Ink narrative language which is an English like language to write interactive fictions. The idea of this exercise is to learn writing parsers and understand connected challenges. The recommended way to go about this exercise is to first write the parser from scratch (starting from pure RegEx) and the use common parsing frameworks or approaches. Here are a few expectations from your program: Your parser library (or cli tool) should expose two functions, parse for taking Ink string and returning a structured data, and format for taking structured Ink data and returning formatted Ink string. It should be able to recognize and handle basic Ink syntax, such as: Knots and Diverts (e.g., == knot_name -> divert_target ) Choices (e.g., * [Choice 1] Text of choice 1 ) Conditional logic (e.g., { condition: True branch | False branch } ) Implement informative error handling for unrecognized syntax. Testing There are no tests for this exercise as of now. You should write your own example Ink samples and check something like format(parse(original_text)) == original_text Tip Since you are writing the parser for Ink, you can also make a CLI tool that executes the story. You can take design inspiration from Inky . Resources Ink Homepage Reference implementations in C#","title":"Ink Language Parser"},{"location":"misc/01-parsing/#ink-language-parser","text":"Develop a simple parser in your preferred programming language that can read and interpret basic constructs of the Ink narrative language which is an English like language to write interactive fictions. The idea of this exercise is to learn writing parsers and understand connected challenges. The recommended way to go about this exercise is to first write the parser from scratch (starting from pure RegEx) and the use common parsing frameworks or approaches. Here are a few expectations from your program: Your parser library (or cli tool) should expose two functions, parse for taking Ink string and returning a structured data, and format for taking structured Ink data and returning formatted Ink string. It should be able to recognize and handle basic Ink syntax, such as: Knots and Diverts (e.g., == knot_name -> divert_target ) Choices (e.g., * [Choice 1] Text of choice 1 ) Conditional logic (e.g., { condition: True branch | False branch } ) Implement informative error handling for unrecognized syntax. Testing There are no tests for this exercise as of now. You should write your own example Ink samples and check something like format(parse(original_text)) == original_text Tip Since you are writing the parser for Ink, you can also make a CLI tool that executes the story. You can take design inspiration from Inky .","title":"Ink Language Parser"},{"location":"misc/01-parsing/#resources","text":"Ink Homepage Reference implementations in C#","title":"Resources"},{"location":"misc/np/","text":"Miscellaneous non-programming Topics Warning Work in Progress!","title":"Miscellaneous non-programming Topics"},{"location":"misc/np/#miscellaneous-non-programming-topics","text":"Warning Work in Progress!","title":"Miscellaneous non-programming Topics"},{"location":"misc/rdbms_basics/","text":"RDBMS Basics Here at Skit, we heavily leverage relational databases to persist information flowing through our services. This document is to give a quick grasp of the concepts that we make use of the most when using these systems. This doc should not be considered the definitive guide to understanding about RDBMS systems. For that, we'd suggest going through this or this . A table and all it entails In an RDBMS(Relational Database Management System), all the information is generally stored in a table. We attempt to capture the different properties of such RDBMS tables below: Property Description Column Each column represents a property of the data being stored. Columns are also called attributes. Row Each row represents a record of data. A single row is called a tuple. Schema Represents different tables in a DB and their relationship with each other. Cardinality Number of rows present in a table. If the above table were to be converted into an RDBMS table, it would have the following properties: Has 2 columns/attributes(Property, Description). Has a cardinality of 4. i.e. 4 rows Each tuple contains 2 properties. i.e. columns Constraints These are conditions applicable to the columns of a table which decide whether the data being inserted/updated is valid or not. Constraints can either be at table level or column level. Column level constraints only govern the data that's inserted/updated as a part of that column. Table level constrains are applicable to all the columns in the table. (a deeper dive can be found here ) Normalization It is the process of organizing data efficiently in the database. This is to ensure that there is: No Data redundancy: Same data is not repeated repeated across tables. Data dependency: Data is organized in the way it is dependent on other data. To read more on the topic, we'd suggest going through 1-NF , 2-NF and 3-NF normalization forms which are guidelines to formalize the rules of normalization. Indexing This is one of the most important concepts you will use when dealing with large datasets like we do here at Skit. Indexes are a technique to efficiently retrieve data from a DBMS system on the basis of some properties. As your tables increase in size, accessing those records becomes slower. This is where indexes come to your rescue. The types of indexes generally available are: Index Type Description Primary Index Defined on the primary key of the table. Secondary Index Defined on keys other than the primary key. Can be used to both unique and non-unique columns. Clustering Index Defines the order in which data is physically stored. Since this data can only be ordered in 1 way, there can only be 1 clustering index per table. Indexes are usually built using columns which are commonly used to retrieve records. That's when they're most useful. If an index is built using a given column, said column is referred to as an indexed column . Using SQL queries with indexed columns in where clauses causes the index to be used. This results in faster retrieval of records. Non-indexed columns are searched using a sequential scan. i.e. a scan of all the values of that column in the table till the matching values are found. As is obvious, this is the most sub-optimal way of fetching records. The primary and clustering indexes are based on ordered data. Ordered indexes can be further sub-divided into the following types: Index Type Description Dense Index Creates an index record for every search key value in the table. This makes searching faster but requires more space to store the index. Sparse Index Creates an index record only certain search keys. Usual practice is to use equally distributed search keys so as to get most benefit from sparse indexes. If a key is not present at the nearest index, a sequential scan starts from that point to locate the record. This makes searching slightly slower but optimizes on space. Conclusion We hope this document served as a nice primer on the features of an RDBMS system. These should help mould the decisions you make regarding database schemas and how to optimise those records for retrieval.","title":"RDBMS Basics"},{"location":"misc/rdbms_basics/#rdbms-basics","text":"Here at Skit, we heavily leverage relational databases to persist information flowing through our services. This document is to give a quick grasp of the concepts that we make use of the most when using these systems. This doc should not be considered the definitive guide to understanding about RDBMS systems. For that, we'd suggest going through this or this .","title":"RDBMS Basics"},{"location":"misc/rdbms_basics/#a-table-and-all-it-entails","text":"In an RDBMS(Relational Database Management System), all the information is generally stored in a table. We attempt to capture the different properties of such RDBMS tables below: Property Description Column Each column represents a property of the data being stored. Columns are also called attributes. Row Each row represents a record of data. A single row is called a tuple. Schema Represents different tables in a DB and their relationship with each other. Cardinality Number of rows present in a table. If the above table were to be converted into an RDBMS table, it would have the following properties: Has 2 columns/attributes(Property, Description). Has a cardinality of 4. i.e. 4 rows Each tuple contains 2 properties. i.e. columns","title":"A table and all it entails"},{"location":"misc/rdbms_basics/#constraints","text":"These are conditions applicable to the columns of a table which decide whether the data being inserted/updated is valid or not. Constraints can either be at table level or column level. Column level constraints only govern the data that's inserted/updated as a part of that column. Table level constrains are applicable to all the columns in the table. (a deeper dive can be found here )","title":"Constraints"},{"location":"misc/rdbms_basics/#normalization","text":"It is the process of organizing data efficiently in the database. This is to ensure that there is: No Data redundancy: Same data is not repeated repeated across tables. Data dependency: Data is organized in the way it is dependent on other data. To read more on the topic, we'd suggest going through 1-NF , 2-NF and 3-NF normalization forms which are guidelines to formalize the rules of normalization.","title":"Normalization"},{"location":"misc/rdbms_basics/#indexing","text":"This is one of the most important concepts you will use when dealing with large datasets like we do here at Skit. Indexes are a technique to efficiently retrieve data from a DBMS system on the basis of some properties. As your tables increase in size, accessing those records becomes slower. This is where indexes come to your rescue. The types of indexes generally available are: Index Type Description Primary Index Defined on the primary key of the table. Secondary Index Defined on keys other than the primary key. Can be used to both unique and non-unique columns. Clustering Index Defines the order in which data is physically stored. Since this data can only be ordered in 1 way, there can only be 1 clustering index per table. Indexes are usually built using columns which are commonly used to retrieve records. That's when they're most useful. If an index is built using a given column, said column is referred to as an indexed column . Using SQL queries with indexed columns in where clauses causes the index to be used. This results in faster retrieval of records. Non-indexed columns are searched using a sequential scan. i.e. a scan of all the values of that column in the table till the matching values are found. As is obvious, this is the most sub-optimal way of fetching records. The primary and clustering indexes are based on ordered data. Ordered indexes can be further sub-divided into the following types: Index Type Description Dense Index Creates an index record for every search key value in the table. This makes searching faster but requires more space to store the index. Sparse Index Creates an index record only certain search keys. Usual practice is to use equally distributed search keys so as to get most benefit from sparse indexes. If a key is not present at the nearest index, a sequential scan starts from that point to locate the record. This makes searching slightly slower but optimizes on space.","title":"Indexing"},{"location":"misc/rdbms_basics/#conclusion","text":"We hope this document served as a nice primer on the features of an RDBMS system. These should help mould the decisions you make regarding database schemas and how to optimise those records for retrieval.","title":"Conclusion"},{"location":"react-basics/","text":"REACT BASICS In this document we will be going through some basics of REACT , especially react-hooks since we use that on a daily basis. This document covers the basics of react hooks , some ideologies in React , and some facts that would be helpful to a beginner. We assume that you have a basic familiarity in HTML,CSS & JS. If not we recommend to get a basic understanding of those fields from here and here . Nevertheless we will go through some concepts of react that might be interesting to some ;). Introduction React is a declarative, efficient, and flexible JavaScript library for building user interfaces. It lets you compose complex UIs from small and isolated pieces of code called \u201ccomponents\u201d. In react one might have seen earlier strange mixture of HTML and JavaScript inside each component. React actually uses a language called JSX that allows HTML to be mixed with JavaScript. Not only can you use JSX to return pre-defined HTML elements, you can also create your own. For example instead of rendering h2 elements directly in the class component, you can render the functional component which returns the same thing. So lets start by understanding some fundamental concepts of react. state In React we keep the data in regular JS variables and maintains its own virtual DOM(Document Object Model). So basically whenever you want to update something in the DOM we have to locate the appropriate node and then manually append or remove elements. React then compares the virtual DOM and the actual DOM by checking the application state. It then updates the UI accordingly. For example if we store a counter value and two buttons for increment and decrement. const Timer = () => { const [ counter , setCounter ] = useState ( 0 ); }; We stored the value counter having initial value 0 and a callback function for setting counter value. In this we used a hook useState which we will discuss later on. We should always keep in my mind that Data everytime flows down Using State in a right manner. Do not modify the state directly. State updates maybe asynchronous. State updates are merged. const Timer = () => { const [ counter , setCounter ] = useState ( 0 ); const handleDecrement = () => { setCounter (( prevState ) => prevState - 1 ); }; const handleIncrement = () => { setCounter (( prevState ) => prevState + 1 ); }; return ( < div > < h2 >{ counter }</ h2 > < button onClick = { handleDecrement }> Decrement </ button > < button onClick = { handleIncrement }> Increment </ button > </ div > ); }; We updated the state by calling setCounter in each of the functions handling a button click. The counter displayed on the page will update in real time. Thus, React gets its name because it reacts to state changes. In short, React automatically monitors every component state for changes and updates the DOM appropriately. props Props can be considered as properties of a component which we pass through to define certain aspect of the UI. const Display = ( props ) => { return ( < div > { props . counter ? (< h1 > Yes Positivity </ h1 >) : (< h1 > NO Negativity </ h1 >)} </ div > ) } const Timer = () => { const [ state , setState ] = useState ( \"0\" ) return ( <> < Display counter = { state }/> </> ) } In here you can see we are accessing the counter variable like a props counter in the Display component. component lifecycle In updating the UI , react follows various norms which can be coined to be its lifecycle. It has its phases from initialization to mountin to updating state to unmounting the component. Some lifecycle methods are shouldComponentUpdate() Function: By default, every state or props update re-render the page but this may not always be the desired outcome, sometimes it is desired that updating the page will not be repainted. The shouldComponentUpdate() Function fulfills the requirement by letting React know whether the component\u2019s output will be affected by the update or not. shouldComponentUpdate() is invoked before rendering an already mounted component when new props or state are being received. If returned false then the subsequent steps of rendering will not be carried out. This function can\u2019t be used in the case of forceUpdate(). The Function takes the new Props and new State as the arguments and returns whether to re-render or not. componentDidUpdate() Function: This function is invoked after the component is rerendered i.e. this function gets invoked once after the render() function is executed after the updation of State or Props. You can take a look at the examples given here Here is an example of simple navbar. const Awesomenav = () => { return ( < div > < nav > < ul > < li > Nav1 </ li > < li > Nav2 </ li > < li > Nav3 </ li > < li > Nav4 </ li > </ ul > </ nav > </ div > ); }; export default Awesomenav ; You can write the above piece of code multiple times wherever you need but after a time it becomes tedious. Instead you can follow write once read everywhere principle. import Awesomenav from \"<specified folder>\" //just import it and use it anywhere. < div > < Awesomenav > </ div > You can just import the above piece of code as a component and can use it anyhwere. This is an basic example of how one can use components. Now we would dive a bit into different types of hooks available for us to use. useState hook This hook basically deals with setting up the state of the component. As you would have seen in examples given above we have used the useState to establish an identity of an object , variable in the component. import { useState } from \"react\" ; const App = () => { const [ counter , setCounter ] = useState ( 0 ) ... } In the above example the useState return the state i.e variable counter and a function (setCounter) to set the counter variable. useEffect hook The Effect Hook lets you perform side effects in function components: import { useState , useEffect } from \"react\" ; const Example = () => { const [ count , setCount ] = useState ( 0 ); // Similar to componentDidMount and componentDidUpdate: useEffect(() => { // Update the document title using the browser API document.title = `You clicked ${count} times`; }); return ( < div > < p > You clicked { count } times </ p > < button onClick = {() => setCount ( count + 1 )}> Click me </ button > </ div > ); }; Data fetching, setting up a subscription, and manually changing the DOM in React components are all examples of side effects. The useEffect Hook can be determined as componentDidMount, componentDidUpdate, and componentWillUnmount combined. Exercise for the react basic * There is a exercise folder given in the directory. You have been given the designs for creating a todolist app. Resources followed - https://reactjs.org/docs/getting-started.html","title":"Index"},{"location":"react-basics/#react-basics","text":"In this document we will be going through some basics of REACT , especially react-hooks since we use that on a daily basis. This document covers the basics of react hooks , some ideologies in React , and some facts that would be helpful to a beginner. We assume that you have a basic familiarity in HTML,CSS & JS. If not we recommend to get a basic understanding of those fields from here and here . Nevertheless we will go through some concepts of react that might be interesting to some ;).","title":"REACT BASICS"},{"location":"react-basics/#introduction","text":"React is a declarative, efficient, and flexible JavaScript library for building user interfaces. It lets you compose complex UIs from small and isolated pieces of code called \u201ccomponents\u201d. In react one might have seen earlier strange mixture of HTML and JavaScript inside each component. React actually uses a language called JSX that allows HTML to be mixed with JavaScript. Not only can you use JSX to return pre-defined HTML elements, you can also create your own. For example instead of rendering h2 elements directly in the class component, you can render the functional component which returns the same thing. So lets start by understanding some fundamental concepts of react. state In React we keep the data in regular JS variables and maintains its own virtual DOM(Document Object Model). So basically whenever you want to update something in the DOM we have to locate the appropriate node and then manually append or remove elements. React then compares the virtual DOM and the actual DOM by checking the application state. It then updates the UI accordingly. For example if we store a counter value and two buttons for increment and decrement. const Timer = () => { const [ counter , setCounter ] = useState ( 0 ); }; We stored the value counter having initial value 0 and a callback function for setting counter value. In this we used a hook useState which we will discuss later on. We should always keep in my mind that Data everytime flows down Using State in a right manner. Do not modify the state directly. State updates maybe asynchronous. State updates are merged. const Timer = () => { const [ counter , setCounter ] = useState ( 0 ); const handleDecrement = () => { setCounter (( prevState ) => prevState - 1 ); }; const handleIncrement = () => { setCounter (( prevState ) => prevState + 1 ); }; return ( < div > < h2 >{ counter }</ h2 > < button onClick = { handleDecrement }> Decrement </ button > < button onClick = { handleIncrement }> Increment </ button > </ div > ); }; We updated the state by calling setCounter in each of the functions handling a button click. The counter displayed on the page will update in real time. Thus, React gets its name because it reacts to state changes. In short, React automatically monitors every component state for changes and updates the DOM appropriately. props Props can be considered as properties of a component which we pass through to define certain aspect of the UI. const Display = ( props ) => { return ( < div > { props . counter ? (< h1 > Yes Positivity </ h1 >) : (< h1 > NO Negativity </ h1 >)} </ div > ) } const Timer = () => { const [ state , setState ] = useState ( \"0\" ) return ( <> < Display counter = { state }/> </> ) } In here you can see we are accessing the counter variable like a props counter in the Display component. component lifecycle In updating the UI , react follows various norms which can be coined to be its lifecycle. It has its phases from initialization to mountin to updating state to unmounting the component. Some lifecycle methods are shouldComponentUpdate() Function: By default, every state or props update re-render the page but this may not always be the desired outcome, sometimes it is desired that updating the page will not be repainted. The shouldComponentUpdate() Function fulfills the requirement by letting React know whether the component\u2019s output will be affected by the update or not. shouldComponentUpdate() is invoked before rendering an already mounted component when new props or state are being received. If returned false then the subsequent steps of rendering will not be carried out. This function can\u2019t be used in the case of forceUpdate(). The Function takes the new Props and new State as the arguments and returns whether to re-render or not. componentDidUpdate() Function: This function is invoked after the component is rerendered i.e. this function gets invoked once after the render() function is executed after the updation of State or Props. You can take a look at the examples given here Here is an example of simple navbar. const Awesomenav = () => { return ( < div > < nav > < ul > < li > Nav1 </ li > < li > Nav2 </ li > < li > Nav3 </ li > < li > Nav4 </ li > </ ul > </ nav > </ div > ); }; export default Awesomenav ; You can write the above piece of code multiple times wherever you need but after a time it becomes tedious. Instead you can follow write once read everywhere principle. import Awesomenav from \"<specified folder>\" //just import it and use it anywhere. < div > < Awesomenav > </ div > You can just import the above piece of code as a component and can use it anyhwere. This is an basic example of how one can use components. Now we would dive a bit into different types of hooks available for us to use. useState hook This hook basically deals with setting up the state of the component. As you would have seen in examples given above we have used the useState to establish an identity of an object , variable in the component. import { useState } from \"react\" ; const App = () => { const [ counter , setCounter ] = useState ( 0 ) ... } In the above example the useState return the state i.e variable counter and a function (setCounter) to set the counter variable. useEffect hook The Effect Hook lets you perform side effects in function components: import { useState , useEffect } from \"react\" ; const Example = () => { const [ count , setCount ] = useState ( 0 ); // Similar to componentDidMount and componentDidUpdate: useEffect(() => { // Update the document title using the browser API document.title = `You clicked ${count} times`; }); return ( < div > < p > You clicked { count } times </ p > < button onClick = {() => setCount ( count + 1 )}> Click me </ button > </ div > ); }; Data fetching, setting up a subscription, and manually changing the DOM in React components are all examples of side effects. The useEffect Hook can be determined as componentDidMount, componentDidUpdate, and componentWillUnmount combined. Exercise for the react basic * There is a exercise folder given in the directory. You have been given the designs for creating a todolist app.","title":"Introduction"},{"location":"react-basics/#resources-followed","text":"- https://reactjs.org/docs/getting-started.html","title":"Resources followed"}]}